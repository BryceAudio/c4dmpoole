
<!-- This document was automatically generated with bibtex2html 1.98
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     /usr/bin/bibtex2html -nodoc -dl -a -noabstract -nokeywords -o pubs2018_raw publications_bibtex/pubs2018.bib  -->


<dl>

<dt>
[<a name="benetos2018approachesanalysis">1</a>]
</dt>
<dd>
E&nbsp;BENETOS, D&nbsp;STOWELL, and M&nbsp;PLUMBLEY.
 Approaches to complex sound scene analysis.
 In T&nbsp;Virtanen, M&nbsp;PLUMBLEY, and D&nbsp;Ellis, editors, <em>Computational
  Analysis of Sound Scenes and Events</em>, number&nbsp;8 in Signals &amp; Communication,
  pages 215--242. Springer International Publishing, 1 edition, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#benetos2018approachesanalysis">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-63450-0">DOI</a>&nbsp;| 
<a href="http://www.springer.com/gb/book/9783319634494">http</a>&nbsp;]

</dd>


<dt>
[<a name="choi2018thetagging">2</a>]
</dt>
<dd>
K&nbsp;Choi, G&nbsp;Fazekas, M&nbsp;Sandler, and K&nbsp;Cho.
 The effects of noisy labels on deep convolutional neural networks for
  music tagging.
 <em>IEEE Transactions on Emerging Topics in Computational
  Intelligence</em>, X(X (in press)), 2018.
 date-added: 2017-12-21 19:00:24 +0000 date-modified: 2017-12-21
  19:15:46 +0000 keywords: evaluation, music tagging, deep learning, CNN
  bdsk-url-1: https://arxiv.org/pdf/1706.02361.pdf bdsk-url-2:
  https://dx.doi.org/10.1109/TETCI.2017.2771298.
[&nbsp;<a href="pubs2018_raw_bib.html#choi2018thetagging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TETCI.2017.2771298">DOI</a>&nbsp;| 
<a href="https://arxiv.org/pdf/1706.02361.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="mesaros2018detectionchallenge">3</a>]
</dt>
<dd>
A&nbsp;Mesaros, T&nbsp;Heittola, E&nbsp;Benetos, P&nbsp;Foster, M&nbsp;Lagrange, T&nbsp;Virtanen, and
  M&nbsp;Plumbley.
 Detection and classification of acoustic scenes and events: Outcome
  of the dcase 2016 challenge.
 <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>,
  26:379--393, Feb 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mesaros2018detectionchallenge">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2017.2778423">DOI</a>&nbsp;| 
<a href="http://ieeexplore.ieee.org/document/8123864/">http</a>&nbsp;]

</dd>


<dt>
[<a name="panteli2018acorpora">4</a>]
</dt>
<dd>
M&nbsp;PANTELI, E&nbsp;BENETOS, and S&nbsp;DIXON.
 A review of manual and computational approaches for the study of
  world music corpora.
 <em>Journal of New Music Research</em>, 47:176--189, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#panteli2018acorpora">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/09298215.2017.1418896">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="skach2018embodiedarts">5</a>]
</dt>
<dd>
S&nbsp;SKACH, A&nbsp;XAMBO, L&nbsp;TURCHET, A&nbsp;Stolfi, RL&nbsp;STEWART, and MHE BARTHET.
 Embodied interactions with e-textiles and the internet of sounds for
  performing arts.
 Stockholm, Sweden, Mar 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#skach2018embodiedarts">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3173225.3173272">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2018perceptioncues">6</a>]
</dt>
<dd>
T&nbsp;STOCKMAN and S&nbsp;Wilkie.
 Perception of objects that move in depth, using ecologically valid
  audio cues.
 <em>Applied Acoustics</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stockman2018perceptioncues">bib</a>&nbsp;]

</dd>
</dl><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
